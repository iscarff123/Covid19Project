{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a parallelizing function\n",
    "def parallel1(data, func, n_cores = 25):\n",
    "    ### Split data by state into 25 sections\n",
    "    splits = np.array_split(data[\"State\"].unique(), 25)\n",
    "    \n",
    "    ### Create empty list\n",
    "    data_split = []\n",
    "    \n",
    "    ### Add each split dataframe to the list\n",
    "    for i in range(25):\n",
    "        data_split.append(data[data[\"State\"].isin(list(splits[i]))])\n",
    "    \n",
    "    ### Run \n",
    "    pool = Pool(n_cores)\n",
    "    data1 = pd.concat(pool.map(func, data_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define function to create new cases data\n",
    "def newCases1(data):\n",
    "    changeInCases = []\n",
    "    ### For each state.\n",
    "    for state in data[\"State\"].unique():\n",
    "        ### For each county in the state\n",
    "        for county in data[\"County Name\"][data[\"State\"] == state].unique():\n",
    "            ### Calculate diff in case for each day, keep first day\n",
    "            changeInCases.extend(abs(np.diff(data[\"Total Cases\"][(data[\"County Name\"] == county) &\n",
    "                                                                         (data[\"State\"] == state)],\n",
    "                                             prepend = data[\"Total Cases\"][(data[\"County Name\"] == county) &\n",
    "                                                                         (data[\"State\"] == state)].iloc[0])))\n",
    "    ### Add to data\n",
    "    data[\"New Cases\"] = changeInCases\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define function to create new deaths data\n",
    "def newDeaths1(data):\n",
    "    changeInDeaths = []\n",
    "    ### For each state.\n",
    "    for state in data[\"State\"].unique():\n",
    "        ### For each county in the state\n",
    "        for county in data[\"County Name\"][data[\"State\"] == state].unique():\n",
    "            ### Calculate diff in case for each day, keep first day\n",
    "            changeInDeaths.extend(abs(np.diff(data[\"Total Deaths\"][(data[\"County Name\"] == county) &\n",
    "                                                                           (data[\"State\"] == state)],\n",
    "                                             prepend = data[\"Total Deaths\"][(data[\"County Name\"] == county) &\n",
    "                                                                           (data[\"State\"] == state)].iloc[0])))\n",
    "            \n",
    "    ### Add to data\n",
    "    data[\"New Deaths\"] = changeInDeaths\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a parallelizing function\n",
    "def parallel2(data, func, n_cores = 25):\n",
    "    ### Split data by state into 25 sections\n",
    "    splits = np.array_split(data[\"State\"].unique(), 25)\n",
    "    \n",
    "    ### Create empty list\n",
    "    data_split = []\n",
    "    \n",
    "    ### Add each split dataframe to the list\n",
    "    for i in range(25):\n",
    "        data_split.append(data[data[\"State\"].isin(list(splits[i]))])\n",
    "    \n",
    "    pool = Pool(n_cores)\n",
    "    data1 = pd.concat(pool.map(func, data_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define function to create new cases data\n",
    "def newCases2(data):\n",
    "    changeInCases = []\n",
    "    ### For each state.\n",
    "    for state in data[\"State\"].unique():\n",
    "        ### Calculate diff in case for each day, keep first day\n",
    "        changeInCases.extend(abs(np.diff(data[\"TotalCases\"][data[\"State\"] == state],\n",
    "                                         prepend = data[\"TotalCases\"][data[\"State\"] == state].iloc[0])))\n",
    "    ### Add to data\n",
    "    data[\"New Cases\"] = changeInCases\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define function to create new deaths data\n",
    "def newDeaths2(data):\n",
    "    changeInDeaths = []\n",
    "    ### For each state.\n",
    "    for state in data[\"State\"].unique():\n",
    "        ### Calculate diff in case for each day, keep first day\n",
    "        changeInDeaths.extend(abs(np.diff(data[\"TotalDeaths\"][data[\"State\"] == state],\n",
    "                                         prepend = data[\"TotalDeaths\"][data[\"State\"] == state].iloc[0])))\n",
    "            \n",
    "    ### Add to data\n",
    "    data[\"New Deaths\"] = changeInDeaths\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all():\n",
    "\n",
    "    ### Number of confirmed cases by county\n",
    "    !curl https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_confirmed_usafacts.csv --output data/cases.csv\n",
    "\n",
    "    ### Number of confirmed deaths by county\n",
    "    !curl https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_deaths_usafacts.csv --output data/deaths.csv\n",
    "\n",
    "    ### Total Cases\n",
    "    cases = pd.read_csv(\"data/cases.csv\")\n",
    "\n",
    "    odd = \"Unnamed: \" + str(len(cases.columns) - 1)\n",
    "\n",
    "    if (cases.columns[-1] == odd):\n",
    "        cases = cases.drop(columns = cases.columns[-1])\n",
    "\n",
    "    cases\n",
    "\n",
    "    ### Total Deaths\n",
    "    deaths = pd.read_csv(\"data/deaths.csv\")\n",
    "\n",
    "    if (cases.columns[-1] == odd):\n",
    "        deaths = deaths.drop(columns = deaths.columns[-1])\n",
    "\n",
    "    deaths\n",
    "\n",
    "    ### Total Population\n",
    "    population = pd.read_csv(\"data/population.csv\")\n",
    "    population\n",
    "\n",
    "    #### County Data\n",
    "\n",
    "    ### Remove Wade Hampton Area\n",
    "    cases = cases.drop(list(cases[cases[\"County Name\"] == \"Wade Hampton Census Area\"].index))\n",
    "\n",
    "    ### New York City Unallocated/Probable\n",
    "    cases = cases.drop(list(cases[cases[\"County Name\"] == \"New York City Unallocated/Probable\"].index))\n",
    "\n",
    "    ### Remove Grand Princess Cruise Ship\n",
    "    cases = cases.drop(list(cases[cases[\"County Name\"] == \"Grand Princess Cruise Ship\"].index))\n",
    "\n",
    "\n",
    "    #### Deaths Data\n",
    "    ### Remove Wade Hampton Area\n",
    "    deaths = deaths.drop(list(deaths[deaths[\"County Name\"] == \"Wade Hampton Census Area\"].index))\n",
    "\n",
    "    ### New York City Unallocated/Probable\n",
    "    deaths = deaths.drop(list(deaths[deaths[\"County Name\"] == \"New York City Unallocated/Probable\"].index))\n",
    "\n",
    "    ### Remove Grand Princess Cruise Ship\n",
    "    deaths = deaths.drop(list(deaths[deaths[\"County Name\"] == \"Grand Princess Cruise Ship\"].index))\n",
    "\n",
    "    cases = cases.rename(columns = {\"State\" : \"StateABV\"})\n",
    "    cases\n",
    "\n",
    "    deaths = deaths.rename(columns = {\"State\" : \"StateABV\"})\n",
    "    deaths\n",
    "\n",
    "    ### County FIPS\n",
    "    countyFIPS = pd.read_csv(\"data/countyFIPS.csv\")\n",
    "    countyFIPS\n",
    "\n",
    "    ### State FIPS\n",
    "    stateFIPS = pd.read_csv(\"data/stateFIPS.csv\")\n",
    "    stateFIPS\n",
    "\n",
    "    ### Drop cases county labels\n",
    "    cases = cases.drop(columns = \"County Name\")\n",
    "    cases\n",
    "\n",
    "    ### Add County Name from countyFIPS\n",
    "    cases = cases.merge(countyFIPS, how = \"left\")\n",
    "    cases\n",
    "\n",
    "    ### Add State names from stateFIPS\n",
    "    cases = cases.merge(stateFIPS, how = \"left\")\n",
    "    cases\n",
    "\n",
    "    ### Drop deaths county labels\n",
    "    deaths = deaths.drop(columns = \"County Name\")\n",
    "    deaths\n",
    "\n",
    "    ### Add County Name from countyFIPS\n",
    "    deaths = deaths.merge(countyFIPS, how = \"left\")\n",
    "    deaths\n",
    "\n",
    "    ### Add State names from stateFIPS\n",
    "    deaths = deaths.merge(stateFIPS, how = \"left\")\n",
    "    deaths\n",
    "\n",
    "    ### Drop population county and state labels\n",
    "    population = population.drop(columns = \"County Name\")\n",
    "    population\n",
    "\n",
    "    ### Add County Name from countyFIPS\n",
    "    population = population.merge(countyFIPS, how = \"left\")\n",
    "    population\n",
    "\n",
    "    ### Unpivot cases data\n",
    "    cases = pd.melt(cases, id_vars = ['County Name', \"State\", \"StateABV\", \"countyFIPS\", \"stateFIPS\"],\n",
    "                     value_vars = cases.columns[3:-2],\n",
    "                     var_name = \"Date\", value_name = \"Cases\")\n",
    "\n",
    "    cases\n",
    "\n",
    "    ### Unpivot death data\n",
    "    deaths = pd.melt(deaths, id_vars = ['County Name', \"State\", \"StateABV\", \"countyFIPS\", \"stateFIPS\"],\n",
    "                     value_vars = list(deaths.columns[3:-2]),\n",
    "                     var_name = \"Date\", value_name = \"Deaths\")\n",
    "\n",
    "    deaths\n",
    "\n",
    "    ### Merge dataframes\n",
    "    cases_deaths = cases.merge(deaths, on = [\"State\", \"StateABV\", \"County Name\", \"Date\", \"countyFIPS\", \"stateFIPS\"])\n",
    "    cases_deaths\n",
    "\n",
    "    ### Merge dataframes\n",
    "    cases_deaths = cases_deaths.merge(population, on = [\"countyFIPS\",\"County Name\"], how = \"left\")\n",
    "\n",
    "    ### Sort\n",
    "    cases_deaths = cases_deaths.astype({\"Date\" : \"datetime64\"})\n",
    "    cases_deaths = cases_deaths.sort_values([\"State\",\"County Name\",\"Date\"], ascending = [True, True, True])\n",
    "\n",
    "\n",
    "    ### Rename population and cases\n",
    "    cases_deaths = cases_deaths.rename(columns = {\"Cases\" : \"Total Cases\",\n",
    "                                                  \"Deaths\" : \"Total Deaths\"})\n",
    "\n",
    "    cases_deaths = cases_deaths.reset_index().drop(columns = \"index\")\n",
    "    cases_deaths\n",
    "\n",
    "    cases_deaths.info()\n",
    "\n",
    "    cases_deaths = cases_deaths.astype({\"County Name\" : \"category\",\n",
    "                                        \"State\" : \"category\",\n",
    "                                        \"countyFIPS\" : \"str\",\n",
    "                                        \"stateFIPS\" : \"str\"})\n",
    "    cases_deaths.info()\n",
    "\n",
    "    ### First six states end where DC begins\n",
    "    firstSix = cases_deaths[:list(cases_deaths[\"countyFIPS\"][cases_deaths[\"State\"] == \"DC\"].index)[0]]\n",
    "    firstSix\n",
    "\n",
    "    ### Create a new column with the fixed FIPS codes\n",
    "    firstSix.insert(2,\"countyFIPS2\", '0' + firstSix[\"countyFIPS\"])\n",
    "    firstSix\n",
    "\n",
    "    ### Drop the old FIPS codes and rename the new FIPS codes column\n",
    "    firstSix = firstSix.drop(columns = \"countyFIPS\")\n",
    "    firstSix = firstSix.rename(columns = {\"countyFIPS2\" : \"countyFIPS\"})\n",
    "    firstSix\n",
    "\n",
    "    firstSixIndex = np.arange(start = 0, stop = list(cases_deaths[\"countyFIPS\"][cases_deaths[\"State\"] == \"DC\"].index)[0])\n",
    "    cases_deaths = cases_deaths.drop(firstSixIndex)\n",
    "    cases_deaths\n",
    "\n",
    "    cases_deaths = pd.concat([firstSix,cases_deaths])\n",
    "    cases_deaths\n",
    "\n",
    "    cases_deaths.info()\n",
    "\n",
    "    cases_deaths2 = cases_deaths[cases_deaths[\"County Name\"] != \"Statewide Unallocated\"]\n",
    "    cases_deaths2 = cases_deaths2.reset_index()\n",
    "    cases_deaths2 = cases_deaths2.drop(columns = \"index\")\n",
    "    cases_deaths2\n",
    "\n",
    "    ### First for Alabama\n",
    "    ### Aggregate data\n",
    "    StateData = cases_deaths[cases_deaths['State'] == \"Alabama\"].groupby(\"Date\").agg(\n",
    "            TotalCases = pd.NamedAgg(column = \"Total Cases\", aggfunc = sum),\n",
    "            TotalDeaths = pd.NamedAgg(column = \"Total Deaths\", aggfunc = sum),\n",
    "            Population = pd.NamedAgg(column = \"Population\", aggfunc = sum))\n",
    "\n",
    "    ### Make a vector of the state and its FIPS\n",
    "    state = np.repeat(\"Alabama\", len(cases_deaths[\"Date\"].unique()))\n",
    "    stateABV = np.repeat(\"AL\", len(cases_deaths[\"Date\"].unique()))\n",
    "    statefips = np.repeat('1', len(cases_deaths[\"Date\"].unique()))\n",
    "\n",
    "    ### Grab dates\n",
    "    date = cases_deaths[\"Date\"].unique()\n",
    "\n",
    "    ### Insert into State Data\n",
    "    StateData.insert(0, \"stateFIPS\", statefips)\n",
    "    StateData.insert(0, \"StateABV\", stateABV)\n",
    "    StateData.insert(0, \"State\", state)\n",
    "    StateData.insert(0, \"Date\", date)\n",
    "\n",
    "    ### Now the rest\n",
    "    for state, fipsNum, stateABV in zip(cases_deaths[\"State\"].unique()[1:], cases_deaths[\"stateFIPS\"].unique()[1:], \n",
    "                                        cases_deaths[\"StateABV\"].unique()[1:]) :\n",
    "        ### Aggregate data\n",
    "        myStateData = cases_deaths[cases_deaths['State'] == state].groupby(\"Date\").agg(\n",
    "            TotalCases = pd.NamedAgg(column = \"Total Cases\", aggfunc = sum),\n",
    "            TotalDeaths = pd.NamedAgg(column = \"Total Deaths\", aggfunc = sum),\n",
    "            Population = pd.NamedAgg(column = \"Population\", aggfunc = sum))\n",
    "\n",
    "        ### Make a vector of the state/fips and grab dates\n",
    "        mystate = np.repeat(state, len(cases_deaths[\"Date\"].unique()))\n",
    "        mystateABV = np.repeat(stateABV, len(cases_deaths[\"Date\"].unique()))\n",
    "        mystatefips = np.repeat(fipsNum, len(cases_deaths[\"Date\"].unique()))\n",
    "        mydate = cases_deaths[\"Date\"].unique()\n",
    "\n",
    "        ### Insert data\n",
    "        myStateData.insert(0, \"stateFIPS\", mystatefips)\n",
    "        myStateData.insert(0, \"StateABV\", mystateABV)\n",
    "        myStateData.insert(0, \"State\", state)\n",
    "        myStateData.insert(0, \"Date\", date)\n",
    "\n",
    "        ### Stack state datas\n",
    "        StateData = pd.concat([StateData, myStateData])\n",
    "\n",
    "    ### Reset indicies\n",
    "    StateData = StateData.set_index(np.arange(0,len(StateData)))\n",
    "\n",
    "    StateData\n",
    "\n",
    "    ### First for date\n",
    "    ### Aggregate data\n",
    "    USAData = StateData[StateData['Date'] == StateData[\"Date\"].unique()[0]].groupby(\"Date\").agg(\n",
    "            TotalCases = pd.NamedAgg(column = \"TotalCases\", aggfunc = sum),\n",
    "            TotalDeaths = pd.NamedAgg(column = \"TotalDeaths\", aggfunc = sum),\n",
    "            Population = pd.NamedAgg(column = \"Population\", aggfunc = sum))\n",
    "\n",
    "    ### Insert into usaData\n",
    "    USAData.insert(0, \"Date\", StateData[\"Date\"].unique()[0])\n",
    "    USAData.insert(0, \"Country\", \"United States\")\n",
    "\n",
    "\n",
    "    ### For the rest of dates\n",
    "    for day in StateData[\"Date\"].unique()[1:]:\n",
    "        ### Aggregate data\n",
    "        myUSAData = StateData[StateData['Date'] == day].groupby(\"Date\").agg(\n",
    "            TotalCases = pd.NamedAgg(column = \"TotalCases\", aggfunc = sum),\n",
    "            TotalDeaths = pd.NamedAgg(column = \"TotalDeaths\", aggfunc = sum),\n",
    "            Population = pd.NamedAgg(column = \"Population\", aggfunc = sum))\n",
    "\n",
    "        ### Insert date into data\n",
    "        myUSAData.insert(0, \"Date\", day)\n",
    "        myUSAData.insert(0, \"Country\", \"United States\")\n",
    "\n",
    "        ### Stack state datas\n",
    "        USAData = pd.concat([USAData, myUSAData])\n",
    "\n",
    "\n",
    "\n",
    "    ### Reset indicies\n",
    "    USAData = USAData.set_index(np.arange(0,len(USAData)))\n",
    "\n",
    "    USAData\n",
    "\n",
    "    cases_deaths2 = parallel1(cases_deaths2, newCases1)\n",
    "    cases_deaths2\n",
    "\n",
    "    cases_deaths2 = parallel1(cases_deaths2, newDeaths1)\n",
    "    cases_deaths2\n",
    "\n",
    "    StateData = parallel2(StateData, newCases2)\n",
    "    StateData\n",
    "\n",
    "    StateData = parallel2(StateData, newDeaths2)\n",
    "    StateData\n",
    "\n",
    "    ### New Cases\n",
    "    USAData[\"New Cases\"] = abs(np.diff(USAData[\"TotalCases\"], prepend = USAData[\"TotalCases\"].iloc[0]))\n",
    "\n",
    "    ### New Deaths\n",
    "    USAData[\"New Deaths\"] = abs(np.diff(USAData[\"TotalDeaths\"], prepend = USAData[\"TotalDeaths\"].iloc[0]))\n",
    "\n",
    "    USAData\n",
    "\n",
    "    ### Percent of population that have cases.\n",
    "    cases_deaths2[\"%Cases\"] = np.where(cases_deaths2[\"Population\"] != 0,\n",
    "                                       round((cases_deaths2[\"Total Cases\"] / cases_deaths2[\"Population\"]) * 100, 3),\n",
    "                                       0)\n",
    "\n",
    "    ### Percent of population that have died.\n",
    "    cases_deaths2[\"%Deaths\"] = np.where(cases_deaths2[\"Population\"] != 0,\n",
    "                                        round((cases_deaths2[\"Total Deaths\"] / cases_deaths2[\"Population\"]) * 100, 3),\n",
    "                                        0)\n",
    "\n",
    "    cases_deaths2\n",
    "\n",
    "    ### Percent of population that have cases.\n",
    "    StateData[\"%Cases\"] = np.where(StateData[\"Population\"] != 0,\n",
    "                                   round((StateData[\"TotalCases\"] / StateData[\"Population\"]) * 100, 3),\n",
    "                                   0)\n",
    "\n",
    "    ### Percent of population that have died.\n",
    "    StateData[\"%Deaths\"] = np.where(StateData[\"Population\"] != 0,\n",
    "                                    round((StateData[\"TotalDeaths\"] / StateData[\"Population\"]) * 100, 3),\n",
    "                                    0)\n",
    "\n",
    "    StateData\n",
    "\n",
    "    ### Percent of population that have cases.\n",
    "    USAData[\"%Cases\"] = np.where(USAData[\"Population\"] != 0,\n",
    "                                 round((USAData[\"TotalCases\"] / USAData[\"Population\"]) * 100, 3),\n",
    "                                 0)\n",
    "\n",
    "    ### Percent of population that have died.\n",
    "    USAData[\"%Deaths\"] = np.where(USAData[\"Population\"] != 0,\n",
    "                                  round((USAData[\"TotalDeaths\"] / USAData[\"Population\"]) * 100, 3),\n",
    "                                  0)\n",
    "\n",
    "    USAData\n",
    "\n",
    "    cases_deaths2[\"log(Total Cases)\"] = round(np.log(cases_deaths2[\"Total Cases\"]), 3)\n",
    "\n",
    "    cases_deaths2[\"log(Total Deaths)\"] = round(np.log(cases_deaths2[\"Total Deaths\"]), 3)\n",
    "\n",
    "    cases_deaths2[\"log(New Cases)\"] = round(np.log(cases_deaths2[\"New Cases\"]), 3)\n",
    "\n",
    "    cases_deaths2[\"log(New Deaths)\"] = round(np.log(cases_deaths2[\"New Deaths\"]), 3)\n",
    "\n",
    "    cases_deaths2\n",
    "\n",
    "    StateData[\"log(Total Cases)\"] = round(np.log(StateData[\"TotalCases\"]), 3)\n",
    "\n",
    "    StateData[\"log(Total Deaths)\"] = round(np.log(StateData[\"TotalDeaths\"]), 3)\n",
    "\n",
    "    StateData[\"log(New Cases)\"] = round(np.log(StateData[\"New Cases\"]), 3)\n",
    "\n",
    "    StateData[\"log(New Deaths)\"] = round(np.log(StateData[\"New Deaths\"]), 3)\n",
    "\n",
    "    StateData\n",
    "\n",
    "    USAData[\"log(Total Cases)\"] = round(np.log(USAData[\"TotalCases\"]), 3)\n",
    "\n",
    "    USAData[\"log(Total Deaths)\"] = round(np.log(USAData[\"TotalDeaths\"]), 3)\n",
    "\n",
    "    USAData[\"log(New Cases)\"] = round(np.log(USAData[\"New Cases\"]), 3)\n",
    "\n",
    "    USAData[\"log(New Deaths)\"] = round(np.log(USAData[\"New Deaths\"]), 3)\n",
    "\n",
    "    USAData\n",
    "\n",
    "    StateData = StateData.rename(columns = {\"TotalCases\" : \"Total Cases\",\n",
    "                                            \"TotalDeaths\" : \"Total Deaths\"})\n",
    "    StateData\n",
    "\n",
    "    USAData = USAData.rename(columns = {\"TotalCases\" : \"Total Cases\",\n",
    "                                            \"TotalDeaths\" : \"Total Deaths\"})\n",
    "    USAData\n",
    "\n",
    "    StateData = StateData.astype({\"State\" : \"category\",\n",
    "                                  \"stateFIPS\" : \"str\"})\n",
    "    StateData.info()\n",
    "\n",
    "    USAData = USAData.astype({\"Country\" : \"category\"})\n",
    "    USAData.info()\n",
    "\n",
    "    CountyData = cases_deaths2\n",
    "\n",
    "    ### Google Mobility data\n",
    "    !curl https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv?cachebust=7d0cb7d254d29111 --output data/mobility.csv\n",
    "\n",
    "    GoogleMobility = pd.read_csv(\"data/mobility.csv\", dtype = \"str\")\n",
    "    GoogleMobility\n",
    "\n",
    "    ### Keep only US\n",
    "    GoogleMobility = GoogleMobility[GoogleMobility[\"country_region_code\"] == \"US\"]\n",
    "    GoogleMobility\n",
    "\n",
    "    ### Mobility data for whole country\n",
    "    GoogleUsaMobility = GoogleMobility[GoogleMobility[\"sub_region_1\"].isnull()]\n",
    "\n",
    "    ### Mobility data for states\n",
    "    GoogleStateMobility = GoogleMobility[(GoogleMobility[\"sub_region_1\"].isnull() != True) & (GoogleMobility[\"sub_region_2\"].isnull())]\n",
    "\n",
    "    ### Mobility data for counties\n",
    "    GoogleCountyMobility = GoogleMobility[GoogleMobility[\"sub_region_2\"].isnull() != True]\n",
    "\n",
    "    ### Drop columns from usaMobility\n",
    "    GoogleUsaMobility = GoogleUsaMobility.drop(columns = [\"country_region_code\", \"sub_region_1\",\n",
    "                                              \"sub_region_2\", \"iso_3166_2_code\",\n",
    "                                              \"census_fips_code\"])\n",
    "\n",
    "    ### Drop columns from stateMobility\n",
    "    GoogleStateMobility = GoogleStateMobility.drop(columns = [\"country_region_code\", \"country_region\", \n",
    "                                                  \"sub_region_2\", \"iso_3166_2_code\", \n",
    "                                                  \"census_fips_code\"])\n",
    "\n",
    "    ### Drop columns from countyMobility\n",
    "    GoogleCountyMobility = GoogleCountyMobility.drop(columns = [\"country_region_code\", \"country_region\",\n",
    "                                                    \"sub_region_1\", \"iso_3166_2_code\"])\n",
    "\n",
    "    ### Rename usaMobility columns\n",
    "    GoogleUsaMobility = GoogleUsaMobility.rename(columns = {\"country_region\" : \"Country\",\n",
    "                                                \"date\" : \"Date\",\n",
    "                                                \"retail_and_recreation_percent_change_from_baseline\" : \"%Retail/Rec Change\",\n",
    "                                                \"grocery_and_pharmacy_percent_change_from_baseline\" : \"%Grocery/Pharm Change\",\n",
    "                                                \"parks_percent_change_from_baseline\" : \"%Parks Change\",\n",
    "                                                \"transit_stations_percent_change_from_baseline\" : \"%Transit Change\",\n",
    "                                                \"workplaces_percent_change_from_baseline\" : \"%Workplace Change\",\n",
    "                                                \"residential_percent_change_from_baseline\" : \"%Residential Change\"})\n",
    "    GoogleUsaMobility = GoogleUsaMobility.astype({\"Date\" : \"datetime64\"})\n",
    "\n",
    "\n",
    "    ### Rename stateMobility columns\n",
    "    GoogleStateMobility = GoogleStateMobility.rename(columns = {\"sub_region_1\" : \"State\",\n",
    "                                                \"date\" : \"Date\",\n",
    "                                                \"retail_and_recreation_percent_change_from_baseline\" : \"%Retail/Rec Change\",\n",
    "                                                \"grocery_and_pharmacy_percent_change_from_baseline\" : \"%Grocery/Pharm Change\",\n",
    "                                                \"parks_percent_change_from_baseline\" : \"%Parks Change\",\n",
    "                                                \"transit_stations_percent_change_from_baseline\" : \"%Transit Change\",\n",
    "                                                \"workplaces_percent_change_from_baseline\" : \"%Workplace Change\",\n",
    "                                                \"residential_percent_change_from_baseline\" : \"%Residential Change\"})\n",
    "    GoogleStateMobility = GoogleStateMobility.astype({\"Date\" : \"datetime64\"})\n",
    "\n",
    "\n",
    "    ### Rename countyMobility columns\n",
    "    GoogleCountyMobility = GoogleCountyMobility.rename(columns = {\"sub_region_2\" : \"County Name\",\n",
    "                                                \"census_fips_code\" : \"countyFIPS\",\n",
    "                                                \"date\" : \"Date\",\n",
    "                                                \"retail_and_recreation_percent_change_from_baseline\" : \"%Retail/Rec Change\",\n",
    "                                                \"grocery_and_pharmacy_percent_change_from_baseline\" : \"%Grocery/Pharm Change\",\n",
    "                                                \"parks_percent_change_from_baseline\" : \"%Parks Change\",\n",
    "                                                \"transit_stations_percent_change_from_baseline\" : \"%Transit Change\",\n",
    "                                                \"workplaces_percent_change_from_baseline\" : \"%Workplace Change\",\n",
    "                                                \"residential_percent_change_from_baseline\" : \"%Residential Change\"})\n",
    "    GoogleCountyMobility = GoogleCountyMobility.astype({\"Date\" : \"datetime64\"})\n",
    "\n",
    "\n",
    "    ### Re-label District of Columbia as DC\n",
    "    DCindex = list(GoogleStateMobility[\"State\"][GoogleStateMobility[\"State\"] == \"District of Columbia\"].index)\n",
    "    for index in DCindex:\n",
    "        GoogleStateMobility[\"State\"][index] = \"DC\"\n",
    "\n",
    "    ### Go grab data\n",
    "    !curl https://data.cdc.gov/api/views/9bhg-hcku/rows.csv?accessType=DOWNLOAD --output data/sexage.csv\n",
    "\n",
    "    ### Read in data\n",
    "    DeathsSexAge = pd.read_csv(\"data/sexage.csv\")\n",
    "    DeathsSexAge\n",
    "\n",
    "    DeathsSexAge = DeathsSexAge.drop(columns = [\"Total Deaths\",\n",
    "                                                \"Pneumonia Deaths\",\n",
    "                                                \"Pneumonia and COVID-19 Deaths\",\n",
    "                                                \"Influenza Deaths\", \n",
    "                                                \"Pneumonia, Influenza, or COVID-19 Deaths\",\n",
    "                                                \"Footnote\"])\n",
    "    DeathsSexAge\n",
    "\n",
    "    ### Drop Puerto Rico, Puerto Rico Total\n",
    "    PRindex = list(DeathsSexAge[\"State\"][(DeathsSexAge[\"State\"] == \"Puerto Rico\") | (DeathsSexAge[\"State\"] == \"Puerto Rico Total\")].index)\n",
    "    DeathsSexAge = DeathsSexAge.drop(index = PRindex)\n",
    "    DeathsSexAge\n",
    "\n",
    "\n",
    "    ### Rename DC\n",
    "    DCindex = list(DeathsSexAge[\"State\"][DeathsSexAge[\"State\"] == \"District of Columbia\"].index)\n",
    "    DeathsSexAge[\"State\"][DCindex] = \"DC\"\n",
    "\n",
    "    DeathsSexAge[\"State\"].unique()\n",
    "\n",
    "    ### Go grab data\n",
    "    !curl https://data.cdc.gov/api/views/pj7m-y5uh/rows.csv?accessType=DOWNLOAD --output data/race.csv\n",
    "\n",
    "    ### Read in Data\n",
    "    race = pd.read_csv(\"data/race.csv\")\n",
    "    race\n",
    "\n",
    "    race = race.drop(columns = \"Footnote\")\n",
    "    race\n",
    "\n",
    "    ### Drop NYC.\n",
    "    NYCindex = list(race[\"State\"][race[\"State\"] == \"New York City\"].index)\n",
    "    race = race.drop(index = NYCindex)\n",
    "\n",
    "    ### Rename New York<sup>5</sup> to New York.\n",
    "    NYindex = list(race[\"State\"][race[\"State\"] == \"New York<sup>5</sup>\"].index)\n",
    "    race[\"State\"][NYindex] = \"New York\"\n",
    "\n",
    "    ### Rename DC\n",
    "    DCindex = list(race[\"State\"][race[\"State\"] == \"District of Columbia\"].index)\n",
    "    race[\"State\"][DCindex] = \"DC\"\n",
    "\n",
    "    race[\"State\"].unique()\n",
    "\n",
    "    countDeaths = race[race[\"Indicator\"] == \"Count of COVID-19 deaths\"]\n",
    "    distDeaths = race[race[\"Indicator\"] == \"Distribution of COVID-19 deaths (%)\"]\n",
    "    unweightDeaths = race[race[\"Indicator\"] == \"Unweighted distribution of population (%)\"]\n",
    "    weightDeaths = race[race[\"Indicator\"] == \"Weighted distribution of population (%)\"]\n",
    "\n",
    "    ### Unpivot\n",
    "    countDeaths = pd.melt(countDeaths, id_vars = [\"Data as of\",\"State\", \"Indicator\"],\n",
    "           value_vars = countDeaths.columns[3:9],\n",
    "           var_name = \"Race\", value_name = \"Count of COVID-19 deaths\")\n",
    "    countDeaths\n",
    "\n",
    "    ### Drop Indicator\n",
    "    countDeaths = countDeaths.drop(columns = \"Indicator\")\n",
    "    countDeaths\n",
    "\n",
    "    ### Unpivot\n",
    "    distDeaths = pd.melt(distDeaths, id_vars = [\"Data as of\",\"State\", \"Indicator\"],\n",
    "           value_vars = distDeaths.columns[3:9],\n",
    "           var_name = \"Race\", value_name = \"Distribution of COVID-19 deaths (%)\")\n",
    "    distDeaths\n",
    "\n",
    "    ### Drop Indicator\n",
    "    distDeaths = distDeaths.drop(columns = \"Indicator\")\n",
    "    distDeaths\n",
    "\n",
    "    ### Unpivot\n",
    "    unweightDeaths = pd.melt(unweightDeaths, id_vars = [\"Data as of\",\"State\", \"Indicator\"],\n",
    "           value_vars = unweightDeaths.columns[3:9],\n",
    "           var_name = \"Race\", value_name = \"Unweighted distribution of population (%)\")\n",
    "    unweightDeaths\n",
    "\n",
    "    ### Drop Indicator\n",
    "    unweightDeaths = unweightDeaths.drop(columns = \"Indicator\")\n",
    "    unweightDeaths\n",
    "\n",
    "    ### Unpivot\n",
    "    weightDeaths = pd.melt(weightDeaths, id_vars = [\"Data as of\",\"State\", \"Indicator\"],\n",
    "           value_vars = weightDeaths.columns[3:9],\n",
    "           var_name = \"Race\", value_name = \"Weighted distribution of population (%)\")\n",
    "    weightDeaths\n",
    "\n",
    "    ### Drop Indicator\n",
    "    weightDeaths = weightDeaths.drop(columns = \"Indicator\")\n",
    "    weightDeaths\n",
    "\n",
    "    raceNew = countDeaths.merge(distDeaths, how = \"inner\", on = [\"Data as of\", \"State\", \"Race\"])\n",
    "    raceNew = raceNew.merge(unweightDeaths, how = \"inner\", on = [\"Data as of\", \"State\", \"Race\"])\n",
    "    raceNew = raceNew.merge(weightDeaths, how = \"inner\", on = [\"Data as of\", \"State\", \"Race\"])\n",
    "    raceNew\n",
    "\n",
    "    ### Go grab data\n",
    "    !curl https://www.cdc.gov/nhsn/pdfs/covid19/covid19-NatEst.csv --output data/hospital.csv\n",
    "\n",
    "    ### Load in data\n",
    "    hospital = pd.read_csv(\"data/hospital.csv\")\n",
    "    hospital\n",
    "\n",
    "    ### Drop the Notes & state columns and the first row.\n",
    "    hospital = hospital.drop(columns = [\"state\", \"Notes\"])\n",
    "    hospital = hospital.drop(index = 0)\n",
    "    hospital = hospital.reset_index(drop = True)\n",
    "    hospital\n",
    "\n",
    "    ### Rename columns\n",
    "    hospital = hospital.rename(columns = {'statename' : \"State\", \n",
    "                                          'collectionDate': \"Date\"})\n",
    "    hospital\n",
    "\n",
    "    ### Convert Date into datetime\n",
    "    hospital = hospital.astype({\"Date\" : \"datetime64\"})\n",
    "    hospital\n",
    "\n",
    "    ### Remove Puerto Rico \n",
    "    PRindex = list(hospital[\"State\"][hospital[\"State\"] == \"Puerto Rico\"].index)\n",
    "    hospital = hospital.drop(index = PRindex)\n",
    "\n",
    "    ### Rename DC\n",
    "    DCindex = list(hospital[\"State\"][hospital[\"State\"] == \"District of Columbia\"].index)\n",
    "    hospital[\"State\"][DCindex] = \"DC\"\n",
    "\n",
    "    hospital[\"State\"].unique()\n",
    "\n",
    "    CountyData.to_csv(\"data/countyData.csv\", index = False)\n",
    "    StateData.to_csv(\"data/stateData.csv\", index = False)\n",
    "    USAData.to_csv(\"data/usaData.csv\", index = False)\n",
    "    DeathsSexAge.to_csv(\"data/demoDeaths.csv\", index = False)\n",
    "    raceNew.to_csv(\"data/raceDeaths.csv\", index = False)\n",
    "    hospital.to_csv(\"data/hospitalData.csv\", index = False)\n",
    "    GoogleUsaMobility.to_csv('data/GoogleUsaMobility.csv', index = False)\n",
    "    GoogleStateMobility.to_csv('data/GoogleStateMobility.csv', index = False)\n",
    "    GoogleCountyMobility.to_csv('data/GoogleCountyMobility.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
